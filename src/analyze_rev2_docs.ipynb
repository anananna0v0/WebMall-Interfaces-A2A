{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Rev2 Docs Analysis Notebook\n",
        "\n",
        "This notebook analyzes the JSON file at:\n",
        "\n",
        "`/Users/aaronsteiner/Downloads/rev2_docs_since_2020_01_01.json`\n",
        "\n",
        "It reports:\n",
        "- File size and line count\n",
        "- Number of records\n",
        "- Top-level field presence and type distribution\n",
        "- Length statistics for string and list fields; range and mean for numeric fields\n",
        "- A small sample of records\n",
        "\n",
        "No external dependencies are required beyond the Python standard library.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.12.8 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 10:37:40) [Clang 14.0.6 ]\n",
            "Analyzing: /Users/aaronsteiner/Downloads/rev2_docs_since_2020_01_01.json\n",
            "File size: 5,014,752,861 bytes (4782.44 MB)\n",
            "Approx line count (for NDJSON): 6,309,224\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "from collections import Counter, defaultdict\n",
        "from statistics import mean\n",
        "from typing import Any, Dict, Iterable, List, Tuple, Union\n",
        "\n",
        "FILE_PATH = \"/Users/aaronsteiner/Downloads/rev2_docs_since_2020_01_01.json\"\n",
        "\n",
        "print(f\"Python {sys.version}\")\n",
        "print(f\"Analyzing: {FILE_PATH}\")\n",
        "\n",
        "# Basic file metadata\n",
        "try:\n",
        "    file_size_bytes = os.path.getsize(FILE_PATH)\n",
        "    file_size_mb = file_size_bytes / (1024 * 1024)\n",
        "    print(f\"File size: {file_size_bytes:,} bytes ({file_size_mb:.2f} MB)\")\n",
        "except FileNotFoundError:\n",
        "    print(\"File not found. Check FILE_PATH.\")\n",
        "    raise\n",
        "\n",
        "# Count lines efficiently\n",
        "line_count = 0\n",
        "with open(FILE_PATH, \"rb\") as f:\n",
        "    for _ in f:\n",
        "        line_count += 1\n",
        "print(f\"Approx line count (for NDJSON): {line_count:,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parsed records: 6,309,224\n",
            "First keys sample: ['shop_id', 'ean', 'mpnr', 'price', 'product_id', 'name', 'cat_id', 'id', 'brand', 'shop_cat', 'aid', 'dlv_time', 'desc']\n"
          ]
        }
      ],
      "source": [
        "# Helper functions\n",
        "\n",
        "def try_parse_json_lines(path: str) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Attempt to parse file as NDJSON (one JSON document per line).\"\"\"\n",
        "    records: List[Dict[str, Any]] = []\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for idx, line in enumerate(f, start=1):\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            try:\n",
        "                obj = json.loads(line)\n",
        "                if isinstance(obj, dict):\n",
        "                    records.append(obj)\n",
        "                else:\n",
        "                    # If it is an array per line, extend by dicts only\n",
        "                    if isinstance(obj, list):\n",
        "                        records.extend([x for x in obj if isinstance(x, dict)])\n",
        "            except json.JSONDecodeError as e:\n",
        "                # Fail fast: not valid NDJSON\n",
        "                raise ValueError(f\"Not NDJSON at line {idx}: {e}\")\n",
        "    return records\n",
        "\n",
        "\n",
        "def try_parse_json_array(path: str) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Attempt to parse file as a single JSON array of objects.\"\"\"\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "    if isinstance(data, list):\n",
        "        return [x for x in data if isinstance(x, dict)]\n",
        "    if isinstance(data, dict):\n",
        "        # If it's a dict with a key that holds an array\n",
        "        for k, v in data.items():\n",
        "            if isinstance(v, list) and all(isinstance(x, dict) for x in v):\n",
        "                return v\n",
        "    raise ValueError(\"File is neither NDJSON nor a JSON array of objects.\")\n",
        "\n",
        "\n",
        "def load_records(path: str) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Load records trying NDJSON first, then JSON array.\"\"\"\n",
        "    try:\n",
        "        return try_parse_json_lines(path)\n",
        "    except Exception:\n",
        "        return try_parse_json_array(path)\n",
        "\n",
        "\n",
        "records = load_records(FILE_PATH)\n",
        "print(f\"Parsed records: {len(records):,}\")\n",
        "print(\"First keys sample:\", list(records[0].keys()) if records else [])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Field presence and type statistics\n",
        "\n",
        "def type_name(value: Any) -> str:\n",
        "    if value is None:\n",
        "        return \"null\"\n",
        "    if isinstance(value, bool):\n",
        "        return \"bool\"\n",
        "    if isinstance(value, int) and not isinstance(value, bool):\n",
        "        return \"int\"\n",
        "    if isinstance(value, float):\n",
        "        return \"float\"\n",
        "    if isinstance(value, str):\n",
        "        return \"str\"\n",
        "    if isinstance(value, list):\n",
        "        return \"list\"\n",
        "    if isinstance(value, dict):\n",
        "        return \"dict\"\n",
        "    return type(value).__name__\n",
        "\n",
        "field_presence: Counter[str] = Counter()\n",
        "field_type_counts: Dict[str, Counter[str]] = defaultdict(Counter)\n",
        "\n",
        "for rec in records:\n",
        "    for key, val in rec.items():\n",
        "        field_presence[key] += 1\n",
        "        field_type_counts[key][type_name(val)] += 1\n",
        "\n",
        "num_records = len(records)\n",
        "print(f\"Total records: {num_records:,}\")\n",
        "print(\"Top 20 fields by presence:\")\n",
        "for key, cnt in field_presence.most_common(20):\n",
        "    pct = (cnt / num_records * 100) if num_records else 0\n",
        "    print(f\"- {key}: {cnt} ({pct:.1f}%) | types: {dict(field_type_counts[key])}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Length statistics for strings/lists and numeric summaries\n",
        "\n",
        "from math import isnan\n",
        "\n",
        "string_lengths: Dict[str, List[int]] = defaultdict(list)\n",
        "list_lengths: Dict[str, List[int]] = defaultdict(list)\n",
        "numeric_values: Dict[str, List[float]] = defaultdict(list)\n",
        "\n",
        "for rec in records:\n",
        "    for key, val in rec.items():\n",
        "        if isinstance(val, str):\n",
        "            string_lengths[key].append(len(val))\n",
        "        elif isinstance(val, list):\n",
        "            list_lengths[key].append(len(val))\n",
        "        elif isinstance(val, (int, float)) and not isinstance(val, bool):\n",
        "            if isinstance(val, float) and isnan(val):\n",
        "                continue\n",
        "            numeric_values[key].append(float(val))\n",
        "\n",
        "\n",
        "def summarize_lengths(values: List[int]) -> Dict[str, Union[int, float]]:\n",
        "    if not values:\n",
        "        return {}\n",
        "    return {\n",
        "        \"count\": len(values),\n",
        "        \"min\": min(values),\n",
        "        \"max\": max(values),\n",
        "        \"mean\": round(mean(values), 3),\n",
        "    }\n",
        "\n",
        "\n",
        "def summarize_numeric(values: List[float]) -> Dict[str, Union[int, float]]:\n",
        "    if not values:\n",
        "        return {}\n",
        "    return {\n",
        "        \"count\": len(values),\n",
        "        \"min\": round(min(values), 6),\n",
        "        \"max\": round(max(values), 6),\n",
        "        \"mean\": round(mean(values), 6),\n",
        "    }\n",
        "\n",
        "print(\"String field length summaries (top 20 by count):\")\n",
        "for key, vals in sorted(string_lengths.items(), key=lambda kv: len(kv[1]), reverse=True)[:20]:\n",
        "    print(key, summarize_lengths(vals))\n",
        "\n",
        "print(\"\\nList field length summaries (top 20 by count):\")\n",
        "for key, vals in sorted(list_lengths.items(), key=lambda kv: len(kv[1]), reverse=True)[:20]:\n",
        "    print(key, summarize_lengths(vals))\n",
        "\n",
        "print(\"\\nNumeric field summaries (top 20 by count):\")\n",
        "for key, vals in sorted(numeric_values.items(), key=lambda kv: len(kv[1]), reverse=True)[:20]:\n",
        "    print(key, summarize_numeric(vals))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show some samples\n",
        "\n",
        "SAMPLE_COUNT = 3\n",
        "for i, rec in enumerate(records[:SAMPLE_COUNT], start=1):\n",
        "    print(f\"Record {i}:\")\n",
        "    for k, v in list(rec.items())[:20]:\n",
        "        print(f\"  {k}: {str(v)[:200]}\")\n",
        "    print(\"-\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique value counts by field:\n",
            "- product_id: 692,495\n",
            "- ean: 694,941\n",
            "- mpnr: 970,957\n",
            "- id: 6,309,216\n",
            "\n",
            "Assumed primary product key: product_id\n",
            "Unique products (by product_id): 692,495\n",
            "\n",
            "Title length summary (field: 'name'):\n",
            "{'count': 6309224, 'min': 0, 'max': 30595, 'mean': 56.126}\n",
            "\n",
            "Description length summary (field: 'desc'):\n",
            "{'count': 6308967, 'min': 0, 'max': 32259, 'mean': 423.009}\n"
          ]
        }
      ],
      "source": [
        "# Unique product counts and text length statistics\n",
        "\n",
        "from math import isnan\n",
        "from statistics import mean\n",
        "from typing import Union\n",
        "\n",
        "hashable_types = (str, int, float)\n",
        "\n",
        "unique_values: Dict[str, set] = {\n",
        "    \"product_id\": set(),\n",
        "    \"ean\": set(),\n",
        "    \"mpnr\": set(),\n",
        "    \"id\": set(),\n",
        "}\n",
        "\n",
        "name_lengths: List[int] = []\n",
        "desc_lengths: List[int] = []\n",
        "\n",
        "for rec in records:\n",
        "    for key in unique_values.keys():\n",
        "        val = rec.get(key)\n",
        "        if isinstance(val, float) and isnan(val):\n",
        "            continue\n",
        "        if isinstance(val, hashable_types) and val is not None and val != \"\":\n",
        "            unique_values[key].add(val)\n",
        "\n",
        "    name_val = rec.get(\"name\")\n",
        "    if isinstance(name_val, str):\n",
        "        name_lengths.append(len(name_val))\n",
        "\n",
        "    desc_val = rec.get(\"desc\")\n",
        "    if isinstance(desc_val, str):\n",
        "        desc_lengths.append(len(desc_val))\n",
        "\n",
        "unique_counts = {k: len(v) for k, v in unique_values.items()}\n",
        "\n",
        "# Heuristic: pick the best available unique identifier\n",
        "primary_unique_field_used = None\n",
        "if unique_counts.get(\"product_id\", 0) > 0:\n",
        "    primary_unique_field_used = \"product_id\"\n",
        "elif unique_counts.get(\"ean\", 0) > 0:\n",
        "    primary_unique_field_used = \"ean\"\n",
        "elif unique_counts.get(\"id\", 0) > 0:\n",
        "    primary_unique_field_used = \"id\"\n",
        "else:\n",
        "    primary_unique_field_used = \"mpnr\"\n",
        "\n",
        "primary_unique_product_count = unique_counts.get(primary_unique_field_used, 0)\n",
        "\n",
        "print(\"Unique value counts by field:\")\n",
        "for k, v in unique_counts.items():\n",
        "    print(f\"- {k}: {v:,}\")\n",
        "\n",
        "print(f\"\\nAssumed primary product key: {primary_unique_field_used}\")\n",
        "print(f\"Unique products (by {primary_unique_field_used}): {primary_unique_product_count:,}\")\n",
        "\n",
        "\n",
        "def safe_summary(values: List[int]) -> Dict[str, Union[int, float]]:\n",
        "    if not values:\n",
        "        return {\"count\": 0, \"min\": 0, \"max\": 0, \"mean\": 0.0}\n",
        "    return {\n",
        "        \"count\": len(values),\n",
        "        \"min\": min(values),\n",
        "        \"max\": max(values),\n",
        "        \"mean\": round(mean(values), 3),\n",
        "    }\n",
        "\n",
        "title_length_summary = safe_summary(name_lengths)\n",
        "desc_length_summary = safe_summary(desc_lengths)\n",
        "\n",
        "print(\"\\nTitle length summary (field: 'name'):\")\n",
        "print(title_length_summary)\n",
        "\n",
        "print(\"\\nDescription length summary (field: 'desc'):\")\n",
        "print(desc_length_summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Grouping key: product_id\n",
            "Distinct products: 692,495\n",
            "Total offers (records with a product_id): 6,309,224\n",
            "Mean offers per product: 9.111\n",
            "Quantiles (offers per product):\n",
            "- min: 1\n",
            "- p50: 4\n",
            "- p75: 7\n",
            "- p90: 13\n",
            "- p95: 23\n",
            "- p99: 94\n",
            "- max: 4609\n",
            "\n",
            "Top 10 products by number of offers:\n",
            "- 361833689: 4609\n",
            "- 1715666714: 4555\n",
            "- 474165642: 4441\n",
            "- 620779739: 4404\n",
            "- 82250313: 4344\n",
            "- 933916144: 4333\n",
            "- 1812895161: 4317\n",
            "- 466781994: 4283\n",
            "- 607686873: 4263\n",
            "- 254381862: 4205\n"
          ]
        }
      ],
      "source": [
        "# Distribution of offers per product (quantiles)\n",
        "\n",
        "from collections import Counter\n",
        "from math import ceil, isnan\n",
        "from statistics import mean as stat_mean\n",
        "\n",
        "# Decide which product key to group by\n",
        "candidate_keys = [\n",
        "    locals().get(\"primary_unique_field_used\"),\n",
        "    \"product_id\",\n",
        "    \"ean\",\n",
        "    \"id\",\n",
        "    \"mpnr\",\n",
        "]\n",
        "product_key = next((k for k in candidate_keys if k and any(isinstance(rec.get(k), (str, int, float)) for rec in records)), None)\n",
        "if product_key is None:\n",
        "    raise ValueError(\"Could not determine a suitable product key to group by.\")\n",
        "\n",
        "counts_by_product: Counter = Counter()\n",
        "for rec in records:\n",
        "    val = rec.get(product_key)\n",
        "    if isinstance(val, float) and isnan(val):\n",
        "        continue\n",
        "    if isinstance(val, (str, int, float)) and val is not None and val != \"\":\n",
        "        counts_by_product[val] += 1\n",
        "\n",
        "counts = list(counts_by_product.values())\n",
        "num_products = len(counts)\n",
        "num_offers = sum(counts)\n",
        "\n",
        "print(f\"Grouping key: {product_key}\")\n",
        "print(f\"Distinct products: {num_products:,}\")\n",
        "print(f\"Total offers (records with a {product_key}): {num_offers:,}\")\n",
        "print(f\"Mean offers per product: {stat_mean(counts):.3f}\")\n",
        "\n",
        "if not counts:\n",
        "    raise ValueError(\"No counts available to compute quantiles.\")\n",
        "\n",
        "counts_sorted = sorted(counts)\n",
        "\n",
        "def percentile(sorted_values, p):\n",
        "    if not sorted_values:\n",
        "        return None\n",
        "    n = len(sorted_values)\n",
        "    # Nearest-rank method\n",
        "    rank = ceil(p / 100.0 * n)\n",
        "    idx = max(0, min(n - 1, rank - 1))\n",
        "    return sorted_values[idx]\n",
        "\n",
        "quantiles = {\n",
        "    \"p50\": percentile(counts_sorted, 50),\n",
        "    \"p75\": percentile(counts_sorted, 75),\n",
        "    \"p90\": percentile(counts_sorted, 90),\n",
        "    \"p95\": percentile(counts_sorted, 95),\n",
        "    \"p99\": percentile(counts_sorted, 99),\n",
        "    \"min\": counts_sorted[0],\n",
        "    \"max\": counts_sorted[-1],\n",
        "}\n",
        "\n",
        "print(\"Quantiles (offers per product):\")\n",
        "for k in [\"min\", \"p50\", \"p75\", \"p90\", \"p95\", \"p99\", \"max\"]:\n",
        "    print(f\"- {k}: {quantiles[k]}\")\n",
        "\n",
        "# Show top-N products with most offers\n",
        "TOP_N = 10\n",
        "print(f\"\\nTop {TOP_N} products by number of offers:\")\n",
        "for prod, cnt in counts_by_product.most_common(TOP_N):\n",
        "    print(f\"- {prod}: {cnt}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
