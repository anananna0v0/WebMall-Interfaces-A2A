<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta name="description" content="Comparing Agent Interfaces for Web-based Agents on the WebMall Benchmark" />
    <meta name="keywords" content="WebMall, Agent Interfaces, RAG, MCP, NLWeb, LLM Agents, Benchmark Evaluation" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>MCP vs RAG vs NLWeb vs HTML: An Experimental Comparison of Different Agent Interfaces to the Web</title>
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet" />

    <link rel="stylesheet" href="./static/css/bulma.min.css" />
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css" />
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css" />
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" />
    <link rel="stylesheet" href="./static/css/index.css" />
    <link rel="icon" href="./static/images/favicon.ico" />

    <style>
      .results-table {
        position: relative;
        width: 90vw;
        max-width: 1400px;
        left: 50%;
        transform: translateX(-50%);
        overflow-x: auto;
        margin: 1.5rem 0;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        border-radius: 8px;
      }

      .results-table table {
        width: 100%;
        table-layout: auto;
        font-size: 0.9rem;
        border-collapse: separate;
        border-spacing: 0;
        background: white;
        border-radius: 8px;
        overflow: hidden;
      }

      .results-table th,
      .results-table td {
        padding: 0.75em 0.5em;
        text-align: center;
        border-bottom: 1px solid #e5e7eb;
        vertical-align: middle;
        white-space: nowrap;
      }

      .results-table th:first-child,
      .results-table td:first-child {
        text-align: left;
        white-space: normal;
        word-wrap: break-word;
        min-width: 120px;
        max-width: 200px;
        padding-left: 1em;
      }

      .results-table td[data-type="number"] {
        text-align: center;
        font-family: "Monaco", "Menlo", "Ubuntu Mono", monospace;
        font-weight: 500;
      }

      .results-table thead th {
        background: linear-gradient(135deg, #e2e8f0 0%, #cbd5e0 100%);
        color: #2d3748;
        font-weight: 600;
        font-size: 0.85rem;
        text-transform: uppercase;
        letter-spacing: 0.5px;
        position: sticky;
        top: 0;
        z-index: 10;
      }

      .results-table tbody tr {
        transition: background-color 0.2s ease;
      }

      .results-table tbody tr:hover {
        background-color: #f7fafc;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
      }

      .results-table tbody tr:nth-child(even) {
        background-color: #f9fafb;
      }

      .best-result {
        font-weight: bold;
      }
      .code-block {
        background-color: #1e1e1e;
        color: #d4d4d4;
        padding: 1rem;
        border-radius: 4px;
        overflow-x: auto;
        font-family: "Monaco", "Menlo", "Ubuntu Mono", monospace;
        font-size: 0.875rem;
        margin: 1rem 0;
      }

      .architecture-diagram {
        max-width: 100%;
        margin: 1.5rem auto;
        display: block;
        background-color: #ffffff;
        border-radius: 8px;
        padding: 1rem;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
      }

      .navbar {
        background-color: #fff;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        position: sticky;
        top: 0;
        z-index: 100;
      }

      .navbar-item {
        font-weight: 500;
      }

      .navbar-item:hover {
        background-color: #f5f5f5;
      }

      .text-content-constrained {
        max-width: 800px;
        margin: 0 auto;
      }
    </style>

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
  </head>
  <body>
    <!-- Navigation -->
    <nav class="navbar" role="navigation" aria-label="main navigation">
      <div class="navbar-brand">
        <a class="navbar-item" href="#home">
          <strong>Agent Interface Comparison</strong>
        </a>
      </div>

      <div class="navbar-menu">
        <div class="navbar-start">
          <a class="navbar-item" href="#motivation"> Motivation </a>
          <div class="navbar-item has-dropdown is-hoverable">
            <a class="navbar-link"> Agent Interfaces </a>
            <div class="navbar-dropdown">
              <a class="navbar-item" href="#rag-alternative"> RAG Agent </a>
              <a class="navbar-item" href="#mcp"> MCP Agent </a>
              <a class="navbar-item" href="#nlweb-mcp"> NLWeb Agent </a>
            </div>
          </div>
          <a class="navbar-item" href="#technical"> Technical Details </a>
          <a class="navbar-item" href="#use-case"> Use Case </a>
          <a class="navbar-item" href="#results"> Results </a>
          <a class="navbar-item" href="#running"> Running the Benchmark </a>
          <a class="navbar-item" href="#related-work"> Related Work </a>
          <a class="navbar-item" href="#references"> References </a>
          <a class="navbar-item" href="#feedback"> Feedback </a>
        </div>
      </div>
    </nav>

    <!-- Hero Section -->
    <section class="hero" id="home">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-1 publication-title">
                MCP vs RAG vs NLWeb vs HTML:<br />
                A Comparison of the Effectiveness and Efficiency of Different Agent Interfaces to the Web
              </h1>
              <div class="is-size-5 publication-authors">
                <span class="author-block">
                  <a href="https://www.uni-mannheim.de/dws/people/researchers/phd-students/aaron-steiner/">Aaron Steiner</a>,
                </span>
                <span class="author-block">
                  <a href="https://www.uni-mannheim.de/dws/people/researchers/postdoctoral-research-fellows/dr-ralph-peeters/">Ralph Peeters</a>,
                </span>
                <span class="author-block">
                  <a href="https://www.uni-mannheim.de/dws/people/professors/prof-dr-christian-bizer/">Christian Bizer</a>
                </span>
              </div>
              <div class="is-size-5 publication-authors">
                <span class="author-block">
                  <a href="https://www.uni-mannheim.de/dws/research/focus-groups/web-based-systems-prof-bizer/">
                    Data and Web Science Group, University of Mannheim
                  </a>
                </span>
              </div>
              <div class="column has-text-centered">
                <div class="publication-links">
                  <span class="link-block">
                    <a href="https://github.com/wbsg-uni-mannheim/WebMall-Interfaces" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                    </a>
                  </span>
                  <span class="link-block">
                    <a href="https://wbsg-uni-mannheim.github.io/WebMall/" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-chart-bar"></i>
                      </span>
                      <span>WebMall Benchmark</span>
                    </a>
                  </span>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Motivation Section -->
    <section class="section" id="motivation">
      <div class="container is-max-desktop">
        <!-- Introduction -->
        <div class="columns is-centered has-text-centered">
          <div class="column is-full-width">
            <h2 class="title is-3">1. Introduction</h2>
            <div class="content has-text-justified">
              <p>
                LLM agents use different architectures and interfaces to interact with the World Wide Web. Some agents rely on traditional web
                browsers to
                <b>navigate HTML pages</b> originally designed for human users. Others do not directly access websites but instead retrieve web
                content by <b>querying search engines</b> that have indexed the Web. A third architectural approach assumes that websites expose
                <b>site-specific Web APIs</b>, which agents interact with via the Model Context Protocol (MCP). A fourth architecture, proposed by
                Microsoft under the <b>NLWeb initiative</b>, defines a standardized interface through which agents query individual websites and
                receive responses formatted as structured Schema.org data.
              </p>
              <p>
                This page presents the results of the first experimental comparison of these four architectures, using the
                <b>same set of tasks</b> within an e-commerce scenario. The experiments were conducted across four simulated webshops, each offering
                products via different interfaces. Four corresponding LLM agents — the MCP Agent, RAG Agent, NLWeb Agent, and HTML Agent — are
                evaluated performing the same set of 91 tasks, each using a different method for interacting with the shops.
              </p>
              <p>
                We compare the <b>effectiveness</b> (success rate, F1) of the different agents in solving the tasks, which are grouped into categories
                such as searching for specific products, searching for the cheapest product given concrete or vague requirements, adding products to
                shopping carts, and finally checking out the products and paying for them by credit card. We also assess the <b>efficiency</b> of each
                architecture by measuring task runtime and token usage. The analysis of input and output tokens provides a basis for estimating both
                the operational cost of each agent as well as its energy consumption and environmental impact.
              </p>
              <p>
                In our WebMall experiments, the MCP, RAG, and NLWeb agents achieve comparable — and in many cases higher — task completion rates than
                the Browser Agent (AX+MEM), while using 5–10× fewer tokens. On basic tasks, the NLWeb agent achieves the highest completion rate (up
                to 88% with Claude 4 Sonnet), and the RAG agent shows strong performance across both basic and advanced tasks. All three alternatives
                use significantly fewer tokens than the browser-based agent.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Architecture Diagram -->
    <section class="section" id="architecture">
      <div class="container is-max-desktop">
        <h2 class="title is-3">2. Architectures and Interfaces</h2>
        <div class="content">
          <p>
            The section below describes the four different architectures that we compare in our experimental study as well as the interfaces that
            agents and e-shops use for communication.
          </p>
        </div>
      </div>
    </section>

    <!-- Browser-based Section -->
    <section class="section" id="browser-based">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full-width">
            <h3 class="title is-4">2.1 Browser-based Agent (HTML Agent)</h3>
            <div class="content">
              <p>
                The HTML Agent accesses the webshops via their traditional HTML interfaces intended for human use. We employ the AX+MEM Browser Agent
                from the
                <a href="https://wbsg-uni-mannheim.github.io/WebMall/" target="_blank">WebMall benchmark</a> for our experiments. The agent is
                implemented using the
                <a href="https://github.com/ServiceNow/AgentLab" target="_blank">AgentLab</a>
                library which accompanies
                <a href="https://github.com/ServiceNow/BrowserGym" target="_blank">BrowserGym</a>. The agent uses the accessibility tree (AXTree) of
                HTML pages as observation space and has access to short-term memory, which it can use to store relevant information at each step in
                order to maintain context across longer task sequences.
              </p>

              <h4 class="title is-5">HTML Agent Workflow</h4>
              <p>The HTML agent executes the following interaction loop:</p>
              <ol>
                <li>Navigate to target web page using browser automation</li>
                <li>Parse accessibility tree (AXTree) to understand page content</li>
                <li>Store relevant information in short-term memory</li>
                <li>Execute action (click, type, scroll) based on task requirements</li>
                <li>Repeat interaction cycle until task completion</li>
              </ol>

              <p>
                More details about the AX+MEM Browser Agent are on the
                <a href="https://wbsg-uni-mannheim.github.io/WebMall/" target="_blank">WebMall benchmark</a> page.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- RAG Section -->
    <section class="section" id="rag-alternative">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full-width">
            <h3 class="title is-4">2.2 Agent querying a Search Engine (RAG Agent)</h3>
            <div class="content">
              <p>
                The RAG agent does not directly access the e-shops but interacts with a search engine that has crawled and indexed all pages of all
                e-shops. Our RAG implementation uses
                <a href="https://www.elastic.co/elasticsearch/vector-database" target="_blank">Elasticsearch</a>
                to create a unified search index containing scraped content from all four WebMall shops. Before indexing, we remove navigation
                elements and HTML tags from the pages using the
                <a href="https://github.com/Unstructured-IO/unstructured" target="_blank">Unstructured library</a>. An example of a resulting JSON
                file can be found
                <a href="https://github.com/wbsg-uni-mannheim/WebMall-Interfaces/tree/main/website/examples/rag_elastic.json" target="_blank">here</a
                >. The system generates composite embeddings that combine product titles and descriptions, enabling semantic similarity search. The
                search engine is presented to the agent as a tool that can be called one or multiple times with differing queries to iteratively
                refine the results.
              </p>
              <p>
                The agent leverages the
                <a href="https://www.langchain.com/langgraph" target="_blank">LangGraph</a>
                framework to orchestrate retrieval workflows and incorporates specialized Python functions for e-commerce actions like adding items to
                carts and completing checkouts. More specifically, the RAG agent is implemented as a LangGraph ReAct agent with the following
                available tools:
              </p>
              <ol>
                <li><strong>search_products</strong>: Execute semantic search queries against Elasticsearch (returns title + URL for efficiency)</li>
                <li><strong>get_product_details</strong>: Fetch detailed product information for specific URLs</li>
                <li><strong>add_to_cart_webmall_1-4</strong>: Add products to specific shop carts</li>
                <li><strong>checkout_webmall_1-4</strong>: Complete purchases with customer details</li>
              </ol>
              <h4 class="title is-5">RAG Agent Workflow</h4>
              <p>
                The agent follows a two-phase search approach: first using lightweight searches to identify promising products, then fetching detailed
                information only for relevant items to minimize token usage.
              </p>

              <p>
                For more details about the implementation of the RAG agent please refer to the
                <a href="https://github.com/wbsg-uni-mannheim/WebMall-Interfaces/tree/main/src/rag">RAG source code</a>
                in our repository. The prompt used for defining the agent can be found
                <a
                  href="https://github.com/wbsg-uni-mannheim/WebMall-Interfaces/blob/main/src/rag/benchmark_v2_improved_langgraph.py#L370"
                  target="_blank"
                >
                  here</a
                >.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- MCP Section -->
    <section class="section" id="mcp">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full-width">
            <h3 class="title is-4">2.3 Agent querying Web APIs via MCP (MCP Agent)</h3>
            <div class="content">
              <p>
                The MCP agent interacts with websites through structured APIs provided by website vendors. These APIs are exposed via the
                <a href="https://modelcontextprotocol.io" target="_blank">Model Context Protocol (MCP)</a>, originally proposed by
                <a href="https://www.anthropic.com/news/model-context-protocol" target="_blank">Anthropic</a>. MCP is an open protocol designed to
                standardize communication between LLM applications and external tools or data sources. Instead of parsing unstructured web content, an
                agent (the MCP <em>Host</em>) connects to a dedicated MCP <em>Server</em> that exposes a well-defined set of tools. These tools wrap
                the Web API and can be implemented by the website vendor directly or by a third party.
              </p>
              <p>
                In our setup, we run four independent MCP servers, one for each WebMall shop. These servers expose tools for actions like search, cart
                management, and checkout. However, to simulate a realistic, multi-provider environment, the WebAPIs are heterogeneous - the data
                format and tools returned by each server are intentionally different. This heterogeneity forces the agent to adapt to different API
                responses from each shop, testing its ability to handle diverse, non-standardized data structures, which reflects the reality of
                integrating with multiple independent web services.
              </p>
              <p>
                The agent leverages the same <a href="https://www.langchain.com/langgraph" target="_blank">LangGraph</a> framework as the RAG agent.
                It uses MCP tools exposed by each shop's server for product search, cart management, and checkout operations.
              </p>

              <h4 class="title is-5">MCP Agent Workflow</h4>
              <p>
                The MCP server for each shop exposes its capabilities as tools, which the agent can discover and execute. The workflow is as follows:
              </p>
              <ol>
                <li>
                  <strong>Connection and Discovery:</strong>
                  The agent, acting as an MCP Host, establishes a connection with the MCP Server for a specific shop and discovers the available tools
                  through the protocol's capability negotiation.
                </li>
                <li>
                  <strong>Tool Execution:</strong> The agent invokes tools like <code>search_products</code> or <code>add_to_cart</code> by sending
                  JSON-RPC messages to the server. The server executes the corresponding actions.
                </li>
                <li><strong>Response Handling:</strong> The agent receives a structured but potentially heterogeneous JSON response.</li>
              </ol>
              <p>
                The heterogeneity of WebAPIs is evident in how different shops implement the same functionality. For example, checkout operations have
                completely different signatures and parameter names:
              </p>
              <div class="code-block">
                <pre>
// E-Store Athletes (Shop 1) checkout signature
async def checkout(
    ctx: Context,
    first_name: str,
    last_name: str,
    email: str,
    phone: str,
    address_1: str,
    city: str,
    state: str,
    postcode: str,
    country: str,
    credit_card_number: str,
    credit_card_expiry: str,
    credit_card_cvc: str
) -> str

// TechTalk (Shop 2) checkout signature  
async def checkout_cart_techtalk(
    ctx: Context,
    customer_first_name: str,
    customer_last_name: str,
    customer_email: str,
    customer_phone: str,
    shipping_street: str,
    shipping_city: str,
    shipping_state: str,
    shipping_zip: str,
    shipping_country_code: str,
    payment_card_number: str,
    card_expiration_date: str,
    card_security_code: str
) -> str</pre
                >
              </div>
              <p>
                The heterogeneity extends beyond function signatures to the data structures that are returned by the different search endpoints, e.g.
                each shop used a different set of attribute names and its own product categorization hierarchy.
              </p>
              <p>
                For complete implementation details, refer to the
                <a href="https://github.com/wbsg-uni-mannheim/WebMall-Interfaces/tree/main/src/api_mcp">MCP server code</a>
                in our repository.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- NLWeb + MCP Section -->
    <section class="section" id="nlweb-mcp">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full-width">
            <h3 class="title is-4">2.4 Agent querying NLWeb Sites (NLWeb Agent)</h3>
            <div class="content">
              <p>
                The NLWeb agent interacts with websites through a standardized natural language interface provided by website vendors. The vendor must
                implement and host an "ask" endpoint that accepts natural language queries and returns structured responses according to the
                Schema.org format.
                <a href="https://github.com/nlweb-ai/NLWeb" target="_blank">NLWeb</a>
                (Natural Language for Web), proposed and supported by
                <a href="https://www.microsoft.com/en-us/research/blog/nlweb-a-blueprint-for-web-agent-interfaces/" target="_blank">Microsoft</a>,
                provides a standardized mechanism for this interaction. It operates by leveraging existing semi-structured data, particularly
                Schema.org markup, to create a semantic layer over a website's content.
              </p>
              <p>
                In our implementation, we create one dedicated Elasticsearch index per webshop that enables semantic search of that website's content.
                Each NLWeb server processes natural language queries by generating embeddings and performing cosine similarity search against its
                shop-specific index. Additionally, we create an MCP server per shop to enable other functionality like cart management and checkout
                operations, complementing the <code>ask</code> tool for product search.
              </p>
              <p>
                The agent uses the same <a href="https://www.langchain.com/langgraph" target="_blank">LangGraph</a> framework as the other agents. An
                example of an <code>ask</code> tool call and response can be found
                <a href="https://github.com/wbsg-uni-mannheim/WebMall-Interfaces/blob/main/website/examples/nlweb_query.json" target="_blank">here</a
                >.
              </p>
              <h4 class="title is-5">NLWeb Agent Workflow</h4>
              <p>The agent’s interaction with the NLWeb + MCP interface follows the workflow below:</p>
              <ol>
                <li>
                  <strong>Connection and Discovery:</strong>
                  The agent connects to the NLWeb-enabled MCP server for a specific shop and discovers the available tools.
                </li>
                <li>
                  <strong>Natural Language Query:</strong> The agent sends a natural language query (e.g., "laptops under $1000 with 16GB RAM") to the
                  server by invoking the <code>ask</code> tool.
                </li>
                <li>
                  <strong>Semantic Search Execution:</strong>
                  The server generates an embedding from the query and performs a cosine similarity search against the pre-computed vectors in its
                  dedicated Elasticsearch index.
                </li>
                <li><strong>Standardized Response:</strong> The agent receives a list of products in the standardized Schema.org JSON format.</li>
              </ol>
              <p>
                The complete implementation is available in the
                <a href="https://github.com/wbsg-uni-mannheim/WebMall-Interfaces/tree/main/src/nlweb_mcp">NLWeb + MCP directory</a>. The prompt used
                for the agent can be found
                <a href="https://github.com/wbsg-uni-mannheim/WebMall-Interfaces/blob/main/src/benchmark_nlweb_mcp.py#L282" target="_blank">here</a>.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Technical Details Section -->
    <section class="section" id="technical">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full-width">
            <h2 class="title is-3">2.5 Comparison of the Different Architectures</h2>
            <div class="results-table">
              <table class="table is-striped is-hoverable is-fullwidth">
                <thead>
                  <tr>
                    <th>Aspect</th>
                    <th>RAG</th>
                    <th>MCP</th>
                    <th>NLWeb</th>
                    <th>HTML</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td>
                      <strong>Website Infrastructure</strong>
                    </td>
                    <td colspan="4"></td>
                  </tr>
                  <tr>
                    <td>Data Source</td>
                    <td>Web scraping (HTML)</td>
                    <td>API access</td>
                    <td>API access</td>
                    <td>Real-time HTML + AXTree + Screenshots</td>
                  </tr>
                  <tr>
                    <td>Data Storage</td>
                    <td>Unified Elasticsearch Index</td>
                    <td>Per-Shop Elasticsearch Indices</td>
                    <td>Per-Shop Elasticsearch Indices</td>
                    <td>Browser state only</td>
                  </tr>
                  <tr>
                    <td>Index Content</td>
                    <td>Unstructured Text</td>
                    <td>Structured Product Data</td>
                    <td>Structured Product Data</td>
                    <td>N/A</td>
                  </tr>
                  <tr>
                    <td>Preprocessing</td>
                    <td>HTML cleaning</td>
                    <td>None required</td>
                    <td>Schema.org translation</td>
                    <td>AXTree generation</td>
                  </tr>
                  <tr>
                    <td>Response Format</td>
                    <td>Document fields (title, content, url)</td>
                    <td>Heterogeneous per-shop JSON</td>
                    <td>Standardized Schema.org</td>
                    <td>Multi-modal observations (HTML/AXTree/Visual)</td>
                  </tr>
                  <tr>
                    <td>
                      <strong>Agent Architecture</strong>
                    </td>
                    <td colspan="4"></td>
                  </tr>
                  <tr>
                    <td>Search Type</td>
                    <td>Semantic (KNN on embeddings)</td>
                    <td>Semantic (KNN on embeddings)</td>
                    <td>Semantic (KNN on embeddings)</td>
                    <td>DOM/AXTree traversal + visual navigation</td>
                  </tr>
                  <tr>
                    <td>Communication Protocol</td>
                    <td>Direct Python Functions</td>
                    <td>JSON-RPC via MCP</td>
                    <td>JSON-RPC via MCP</td>
                    <td>Playwright + Chrome DevTools Protocol</td>
                  </tr>
                  <tr>
                    <td>Query Strategy</td>
                    <td>Multi-query generation</td>
                    <td>Multi-query possible per shop</td>
                    <td>Multi-query possible per shop</td>
                    <td>Multi-action sequences per step</td>
                  </tr>
                  <tr>
                    <td>Shop Selection</td>
                    <td>Searches all shops at once</td>
                    <td>Agent selects shops</td>
                    <td>Agent selects shops</td>
                    <td>Sequential shop visits</td>
                  </tr>
                  <tr>
                    <td>
                      <strong>Processing Details</strong>
                    </td>
                    <td colspan="4"></td>
                  </tr>
                  <tr>
                    <td>Embedding Fields</td>
                    <td>Title, Content, Composite</td>
                    <td>Title, Content, Composite</td>
                    <td>Title, Content, Composite</td>
                    <td>N/A</td>
                  </tr>
                  <tr>
                    <td>Embedding Model</td>
                    <td>OpenAI text-embedding-3-small</td>
                    <td>OpenAI text-embedding-3-small</td>
                    <td>OpenAI text-embedding-3-small</td>
                    <td>N/A</td>
                  </tr>
                  <tr>
                    <td>Result Ranking</td>
                    <td>Cosine similarity score</td>
                    <td>Cosine similarity score</td>
                    <td>Cosine similarity score</td>
                    <td>Page order/relevance</td>
                  </tr>
                  <tr>
                    <td>
                      <strong>Agent Capabilities</strong>
                    </td>
                    <td colspan="4"></td>
                  </tr>
                  <tr>
                    <td>Search Refinement</td>
                    <td>Self-evaluation & iteration</td>
                    <td>Self-evaluation & iteration</td>
                    <td>Self-evaluation & iteration</td>
                    <td>Interactive page exploration</td>
                  </tr>
                  <tr>
                    <td>Cross-shop Comparison</td>
                    <td>Native (unified index)</td>
                    <td>Sequential MCP calls</td>
                    <td>Sequential MCP calls</td>
                    <td>Sequential browsing</td>
                  </tr>
                  <tr>
                    <td>Cart Management</td>
                    <td>Python tool functions</td>
                    <td>MCP tool invocation</td>
                    <td>MCP tool invocation</td>
                    <td>Browser interactions</td>
                  </tr>
                  <tr>
                    <td>Checkout Process</td>
                    <td>Direct function calls</td>
                    <td>MCP tool invocation</td>
                    <td>MCP tool invocation</td>
                    <td>Form filling & submission</td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Use Case: E-Commerce Section -->
    <section class="section" id="use-case">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full-width">
            <h2 class="title is-3">3. Use Case: Online Shopping</h2>
            <div class="content">
              <p>
                To evaluate the effectiveness and efficiency of the different agents, we use the
                <a href="https://wbsg-uni-mannheim.github.io/WebMall/" target="_blank">WebMall benchmark</a>. WebMall simulates an online shopping
                environment with four distinct webshops, each offering around 1000 products described with heterogeneous product descriptions. The
                WebMall benchmark includes a diverse set of e-commerce tasks that test different agent capabilities ranging from focused retrieval to
                advanced reasoning about compatible and substitutional products. These tasks are organized into two main categories based on their
                complexity:
              </p>

              <h4 class="title is-5">Basic Tasks</h4>
              <ul>
                <li><strong>Find Specific Product (12 tasks)</strong>: Locate a particular product by name or model number</li>
                <li><strong>Find Cheapest Offer (10 tasks)</strong>: Identify the lowest-priced option for a specific product across shops</li>
                <li>
                  <strong>Products Fulfilling Specific Requirements (11 tasks)</strong>: Find products matching precise technical specifications
                </li>
                <li><strong>Add to Cart (7 tasks)</strong>: Add selected products to the shopping cart</li>
                <li><strong>Checkout (8 tasks)</strong>: Complete the purchase process with payment and shipping information</li>
              </ul>

              <h4 class="title is-5">Advanced Tasks</h4>
              <ul>
                <li>
                  <strong>Cheapest Offer with Specific Requirements (10 tasks)</strong>: Find the most affordable product meeting detailed criteria
                </li>
                <li><strong>Products Satisfying Vague Requirements (8 tasks)</strong>: Interpret and fulfill imprecise or subjective requirements</li>
                <li><strong>Cheapest Offer with Vague Requirements (6 tasks)</strong>: Combine price optimization with fuzzy requirement matching</li>
                <li><strong>Find Substitutes (6 tasks)</strong>: Identify alternative products when the requested item is unavailable</li>
                <li><strong>Find Compatible Products (5 tasks)</strong>: Locate accessories or components compatible with a given product</li>
                <li><strong>End To End (8 tasks)</strong>: Complete full shopping workflows from search to checkout</li>
              </ul>

              <p>
                Further
                <a href="https://wbsg-uni-mannheim.github.io/WebMall/#example-tasks" target="_blank">examples of each task type</a>
                are found on the WebMall benchmark page. The complete task set including the solution for each task is found in the
                <a
                  href="https://github.com/wbsg-uni-mannheim/BrowserGym/blob/main/browsergym/webmall/src/browsergym/webmall/task_sets.json"
                  target="_blank"
                  >WebMall repository</a
                >.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Results Section -->
    <section class="section" id="results">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full-width">
            <h2 class="title is-3">4. Experimental Results</h2>
            <div class="content">
              <p>
                We evaluated each agent interface on the complete WebMall benchmark task set. The evaluation compares the performance of different
                agent architectures: RAG Agent, MCP Agent, and NLWeb Agent. For comparison, we also include results from the strongest-performing
                browser-based agent on the WebMall benchmark, AX+MEM, subsequently referred to as Browser Agent.
              </p>
              <p>
                Every agent interface is evaluated with both GPT-4.1 (gpt-4.1-2025-04-14) and Claude 4 Sonnet (claude-sonnet-4-20250514) to assess
                model-dependent performance variations. Note that our experiments do not utilize prompt caching. Detailed execution logs for all runs
                are available in our
                <a href="https://github.com/wbsg-uni-mannheim/WebMall-Interfaces/tree/main/results/v1" target="_blank">GitHub repository</a>,
                organized by interface type and model. For quick understanding of agent behavior,
                <a href="https://github.com/wbsg-uni-mannheim/WebMall-Interfaces/tree/main/results/v1/shortened_logs" target="_blank"
                  >shortened execution logs</a
                >
                containing one successful task execution per agent interface and model are also available.
              </p>

              <h3 class="title is-4">4.1 Evaluation Metrics</h3>
              <p>We assess performance using four metrics derived from comparing the agent's response against the ground truth solutions:</p>
              <ul>
                <li>
                  <strong>Task Completion Rate</strong>: Binary metric (0 or 1) measuring exact task completion. An agent achieves 1.0 only if no
                  elements are missing and no additional elements are returned.
                </li>
                <li>
                  <strong>Precision</strong>: Fraction of agent-returned URLs that are correct (intersection ÷ total URLs returned). Higher precision
                  means fewer incorrect products.
                </li>
                <li>
                  <strong>Recall</strong>: Fraction of correct URLs that the agent found (intersection ÷ total correct URLs). Higher recall means
                  fewer missing products.
                </li>
                <li><strong>F1 Score</strong>: Harmonic mean of precision and recall.</li>
              </ul>

              <h3 class="title is-4">4.2 Performance by Task Type</h3>
              <p>
                The results are shown in the following tables, sorted by completion rate and categorized by task type. Best results per metric are
                highlighted in bold.
              </p>
              <div id="results-by-type" class="results-table">
                <!-- Results table will be inserted here -->
              </div>

              <h3 class="title is-4">4.3 Performance by Category</h3>
              <p>
                Results grouped by task complexity:
                <strong>Basic</strong> tasks include straightforward operations like finding specific products and simple checkout processes, while
                <strong>Advanced</strong> tasks require complex reasoning such as interpreting vague requirements, finding substitutes, and multi-step
                workflows.
              </p>
              <div id="results-by-category" class="results-table">
                <!-- Results table will be inserted here -->
              </div>

              <h3 class="title is-4">4.4 Cost & Runtime Analysis</h3>
              <p>
                Cost and execution time analysis based on model pricing and actual performance from our experiments. Token prices as of July 2025:
              </p>
              <ul>
                <li>
                  <strong>GPT-4.1</strong>: $2.00/MTok input, $8.00/MTok output (<a
                    href="https://platform.openai.com/docs/models/gpt-4.1"
                    target="_blank"
                    >OpenAI pricing</a
                  >)
                </li>
                <li>
                  <strong>Claude 4 Sonnet</strong>: $3.00/MTok input, $15.00/MTok output (<a
                    href="https://docs.anthropic.com/en/docs/about-claude/models/overview#model-comparison-table"
                    target="_blank"
                    >Anthropic pricing</a
                  >)
                </li>
              </ul>
              <p>
                The total cost of running all experiments across all interfaces and models was approximately
                <strong>$250</strong>. This cost excludes embedding generation (which is negligible at $0.02/MTok) and infrastructure costs. Execution
                times shown are averages per task.
              </p>

              <div id="cost-analysis">
                <!-- Cost tables will be inserted here -->
              </div>

              <h3 class="title is-4">Key Findings</h3>
              <ul>
                <li>
                  <strong>Performance</strong>: Specialized interfaces match or exceed browser-based performance, with NLWeb achieving 88% completion
                  rate on basic tasks.
                </li>
                <li>
                  <strong>Efficiency</strong>: Alternative interfaces use 5-10x fewer tokens than browser-based agents, translating to significant
                  cost savings.
                </li>
                <li>
                  <strong>Speed</strong>: RAG and API-based agents complete tasks faster due to direct data access without page navigation overhead.
                </li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Running the Benchmark Section -->
    <section class="section" id="running">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full-width">
            <h2 class="title is-3">5. Running the Benchmark</h2>
            <div class="content has-text-justified">
              <p>
                To reproduce our experiments or run the benchmarks with your own agent implementations, follow these setup instructions. The complete
                code and documentation are available in our
                <a href="https://github.com/wbsg-uni-mannheim/WebMall-Interfaces" target="_blank">GitHub repository</a>.
              </p>

              <h3 class="title is-4">Prerequisites</h3>
              <ul>
                <li><strong>Python 3.8+</strong>: Required for all agent implementations</li>
                <li><strong>Elasticsearch 8.x</strong>: Running on <code>http://localhost:9200</code></li>
                <li><strong>OpenAI API Key</strong>: For embeddings and LLM calls</li>
                <li><strong>Optional</strong>: Anthropic API key for Claude model support</li>
              </ul>

              <h3 class="title is-4">Quick Start</h3>
              <div class="code-block">
                <pre>
# Clone repository
git clone https://github.com/wbsg-uni-mannheim/WebMall-Interfaces.git
cd WebMall-Interfaces

# Install dependencies  
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env with your API keys

# Index data (required for NLWeb and API MCP)
cd src/nlweb_mcp
python ingest_data.py --shop all --force-recreate

# Run benchmarks
cd ..
python benchmark_nlweb_mcp.py    # NLWeb interface
python benchmark_rag.py          # RAG interface  
python benchmark_api_mcp.py      # API MCP interface</pre
                >
              </div>

              <p>
                For detailed setup instructions and interface-specific configuration, see the
                <a href="https://github.com/wbsg-uni-mannheim/WebMall-Interfaces/blob/main/README.md" target="_blank">main README</a>
                and individual interface documentation in the
                <a href="https://github.com/wbsg-uni-mannheim/WebMall-Interfaces/tree/main/src" target="_blank">src/ directory</a>.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Related Work Section -->
    <section class="section" id="related-work">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full-width">
            <h2 class="title is-3">6. Related Work</h2>
            <div class="content has-text-justified">
              <p>
                The closest related work to our experiments is [<a href="#Song2025">Song 2025</a>], which uses tasks from the WebArena benchmark to
                compare LLM agents that access websites via APIs with agents that browse HTML interfaces. The study concludes that API-based agents
                are more effective than HTML agents, with hybrid agents achieving the best overall performance. A second relevant study is [<a
                  href="#Zhang2025"
                  >Zhang 2025</a
                >], which compares API agents to GUI agents. This paper introduces a set of dimensions for comparing API and GUI agents and reports
                the results of an experimental evaluation using 27 office-related tasks, involving Word, Excel, and PPT.
              </p>
              <p>
                A survey of agents for computer use, including Web agents, is presented by [<a href="#Sager2025">Sager 2025</a>]. [<a
                  href="#Yehudai2025"
                  >Yehudai 2025</a
                >] surveys benchmarks used for evaluating LLM agents, while [<a href="#Petrova2025">Petrova 2025</a>] discusses LLM-based agents in
                the context of the historical development of the Semantic Web and FIPA-based multi-agent systems.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Feedback -->
    <section class="section" id="feedback">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full-width">
            <h2 class="title is-3">7. Feedback</h2>
            <div class="content has-text-justified">
              <p>
                We welcome feedback and contributions via GitHub issues and discussions. Alternatively, you can also contact us directly via email.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- References Section -->
    <section class="section" id="references">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full-width">
            <h2 class="title is-3">References</h2>
            <div class="content has-text-justified">
              <p id="Song2025">
                [Song 2025] Song, Yueqi, et al.:
                <a href="https://arxiv.org/abs/2410.16464" target="_blank"> Beyond Browsing: API-Based Web Agents</a>. arXiv:2410.16464, 2025.
              </p>
              <p id="Zhang2025">
                [Zhang 2025] Zhang, Chaoyun, et al.:
                <a href="https://arxiv.org/abs/2503.11069" target="_blank"> API Agents vs. GUI Agents: Divergence and Convergence</a>.
                arXiv:2503.11069, 2025.
              </p>
              <p id="Sager2025">
                [Sager 2025] Sager, Pascal, et al.:
                <a href="https://arxiv.org/abs/2501.16150" target="_blank"> A Comprehensive Survey of Agents for Computer Use</a>. arXiv:2501.16150,
                2025.
              </p>
              <p id="Yehudai2025">
                [Yehudai 2025] Yehudai, Asaf , et al.:
                <a href="https://arxiv.org/abs/2503.16416" target="_blank"> Survey on Evaluation of LLM-based Agents</a>, arXiv:2503.16416, 2025.
              </p>
              <p id="Petrova2025">
                [Petrova 2025] Petrova, Tatiana, et al.:
                <a href="https://arxiv.org/abs/2507.10644" target="_blank">
                  From Semantic Web and MAS to Agentic AI: A Unified Narrative of the Web of Agents</a
                >. arXiv:2507.10644, 2025.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>

    <footer class="footer">
      <div class="container">
        <div class="content has-text-centered">
          <p>
            This website is licensed under a
            <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"
              >Creative Commons Attribution-ShareAlike 4.0 International License</a
            >.
          </p>
        </div>
      </div>
    </footer>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/interfaces.js"></script>
    <script src="./static/js/results-loader.js"></script>
  </body>
</html>
